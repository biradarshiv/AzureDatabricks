{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19b69a43-2753-4e7b-b681-f9884f07fd5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- MLflow is an open source platform for end-to-end machine learning operations. \n",
    "- Using MLflow, data scientists can track model training experiments; logging parameters, metrics, and other assets. \n",
    "- Machine learning engineers can use MLflow to deploy and manage models, enabling applications to consume the models and use them to inference predictions for new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56481313-f098-4062-9d03-4dfce0d99fad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register and serve models with MLflow\n",
    "\n",
    "Model registration allows MLflow and Azure Databricks to keep track of models; which is important for two reasons:\n",
    "\n",
    "- Registering a model allows you to serve the model for real-time, streaming, or batch inferencing. Registration makes the process of using a trained model easy, as now data scientists don't need to develop application code; the serving process builds that wrapper and exposes a REST API or method for batch scoring automatically.\n",
    "\n",
    "- Registering a model allows you to create new versions of that model over time; giving you the opportunity to track model changes and even perform comparisons between different historical versions of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07a899c3-c2be-4ec2-8caa-8c2623ecc3c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You can then select the option to register the model using the user interface in the experiment viewer.\n",
    "\n",
    "Alternatively, if you want to register the model without reviewing the metrics in the run, you can include the registered_model_name parameter in the log_model method; in which case the model is automatically registered during the experiment run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c664ab8-6977-47a6-a090-b9cdb5bae2ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    # code to train model goes here\n",
    "\n",
    "    # log the model itself (and the environment it needs to be used)\n",
    "    unique_model_name = \"my_model-\" + str(time.time())\n",
    "    mlflow.spark.log_model(spark_model=model,\n",
    "                           artifact_path=unique_model_name\n",
    "                           conda_env=mlflow.spark.get_default_conda_env(),\n",
    "                           registered_model_name=\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7aa69b6f-2459-4e16-b9a9-9692b19d0393",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Using a model for inferencing\n",
    "\n",
    "### The process of using a model to predict labels from new feature data is known as inferencing. \n",
    "\n",
    "You can use MLflow in Azure Databricks to make models available for inferencing in the following ways:\n",
    "\n",
    "- Host the model as a real-time service with an HTTP endpoint to which client applications can make REST requests.\n",
    "- Use the model to perform perpetual streaming inferencing of labels based on a delta table of features, writing the results to an output table.\n",
    "- Use the model for batch inferencing based on a delta table, writing the results of each batch operation to a specific folder.\n",
    "\n",
    "You can deploy a model for inferencing from its page in the Models section of the Azure Databricks portal as shown here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ba64016-98c0-4bfc-ad28-59336cb99a12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c999705d-dbee-4abe-ad53-b06bd04abf14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Workspace/MicrosoftLearnings\n/Workspace/MicrosoftLearnings/dbfs/mlflow_lab\n/dbfs/mlflow_lab\n"
     ]
    }
   ],
   "source": [
    " %sh\n",
    " rm -r /Workspace/MicrosoftLearnings/dbfs/mlflow_lab\n",
    " mkdir /Workspace/MicrosoftLearnings/dbfs/mlflow_lab\n",
    " pwd\n",
    " cd /Workspace/MicrosoftLearnings/dbfs/mlflow_lab\n",
    " pwd\n",
    " cd /dbfs/mlflow_lab\n",
    " pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe16a854-cf23-4ede-a909-5059edb5a4d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2025-09-22 08:02:28--  https://raw.githubusercontent.com/MicrosoftLearning/mslearn-databricks/main/data/penguins.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 9533 (9.3K) [text/plain]\nSaving to: ‘/Workspace/MicrosoftLearnings/dbfs/mlflow_lab/penguins.csv’\n\n     0K .........                                             100% 2.31M=0.004s\n\n2025-09-22 08:02:28 (2.31 MB/s) - ‘/Workspace/MicrosoftLearnings/dbfs/mlflow_lab/penguins.csv’ saved [9533/9533]\n\n"
     ]
    }
   ],
   "source": [
    " %sh\n",
    " rm -r /Workspace/MicrosoftLearnings/dbfs/mlflow_lab\n",
    " mkdir /Workspace/MicrosoftLearnings/dbfs/mlflow_lab\n",
    " wget -O /Workspace/MicrosoftLearnings/dbfs/mlflow_lab/penguins.csv https://raw.githubusercontent.com/MicrosoftLearning/mslearn-databricks/main/data/penguins.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a083b2c-50fd-4c89-b1d7-8e663cb6dea9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Now prepare the data for machine learning.\n",
    "\n",
    "- Remove any incomplete rows\n",
    "- Apply appropriate data types\n",
    "- View a random sample of the data\n",
    "- Split the data into two datasets: one for training, and another for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d885ed7f-e1ba-4b40-830e-14ad1f3322ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Island</th><th>CulmenLength</th><th>CulmenDepth</th><th>FlipperLength</th><th>BodyMass</th><th>Species</th></tr></thead><tbody><tr><td>Torgersen</td><td>39.3</td><td>20.6</td><td>190.0</td><td>3650.0</td><td>0</td></tr><tr><td>Torgersen</td><td>39.2</td><td>19.6</td><td>195.0</td><td>4675.0</td><td>0</td></tr><tr><td>Torgersen</td><td>42.5</td><td>20.7</td><td>197.0</td><td>4500.0</td><td>0</td></tr><tr><td>Biscoe</td><td>37.7</td><td>18.7</td><td>180.0</td><td>3600.0</td><td>0</td></tr><tr><td>Biscoe</td><td>35.9</td><td>19.2</td><td>189.0</td><td>3800.0</td><td>0</td></tr><tr><td>Biscoe</td><td>37.9</td><td>18.6</td><td>172.0</td><td>3150.0</td><td>0</td></tr><tr><td>Biscoe</td><td>40.5</td><td>18.9</td><td>180.0</td><td>3950.0</td><td>0</td></tr><tr><td>Dream</td><td>37.2</td><td>18.1</td><td>178.0</td><td>3900.0</td><td>0</td></tr><tr><td>Dream</td><td>39.2</td><td>21.1</td><td>196.0</td><td>4150.0</td><td>0</td></tr><tr><td>Dream</td><td>39.8</td><td>19.1</td><td>184.0</td><td>4650.0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Torgersen",
         39.3,
         20.6,
         190.0,
         3650.0,
         0
        ],
        [
         "Torgersen",
         39.2,
         19.6,
         195.0,
         4675.0,
         0
        ],
        [
         "Torgersen",
         42.5,
         20.7,
         197.0,
         4500.0,
         0
        ],
        [
         "Biscoe",
         37.7,
         18.7,
         180.0,
         3600.0,
         0
        ],
        [
         "Biscoe",
         35.9,
         19.2,
         189.0,
         3800.0,
         0
        ],
        [
         "Biscoe",
         37.9,
         18.6,
         172.0,
         3150.0,
         0
        ],
        [
         "Biscoe",
         40.5,
         18.9,
         180.0,
         3950.0,
         0
        ],
        [
         "Dream",
         37.2,
         18.1,
         178.0,
         3900.0,
         0
        ],
        [
         "Dream",
         39.2,
         21.1,
         196.0,
         4150.0,
         0
        ],
        [
         "Dream",
         39.8,
         19.1,
         184.0,
         4650.0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Island",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CulmenLength",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "CulmenDepth",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "FlipperLength",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "BodyMass",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "Species",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 240  Testing Rows: 102\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "   \n",
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"file:/Workspace/MicrosoftLearnings/dbfs/mlflow_lab/penguins.csv\")\n",
    "data = data.dropna().select(col(\"Island\").astype(\"string\"),\n",
    "                            col(\"CulmenLength\").astype(\"float\"),\n",
    "                            col(\"CulmenDepth\").astype(\"float\"),\n",
    "                            col(\"FlipperLength\").astype(\"float\"),\n",
    "                            col(\"BodyMass\").astype(\"float\"),\n",
    "                            col(\"Species\").astype(\"int\")\n",
    "                          )\n",
    "display(data.sample(0.2).limit(10))\n",
    "\n",
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "print (\"Training Rows:\", train.count(), \" Testing Rows:\", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7c03b78-a497-4e10-8ef3-8afa28a587d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Run an MLflow experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b67b1473-8431-480a-a4b4-5609b996ec82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You can use the same libraries and techniques you normally use to train and evaluate a model (in this case, we’ll use the Spark MLLib library), but do so within the context of an MLflow experiment that includes additional commands to log important metrics and information during the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fac1a10e-4270-47a3-8a0b-2471c691c94f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model...\naccuracy: 0.9313725490196079\nweightedRecall: 0.9313725490196079\nweightedPrecision: 0.9406108597285068\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208b524f215a45b09fb6eb5c099f313b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment run complete.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import time\n",
    "   \n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    catFeature = \"Island\"\n",
    "    numFeatures = [\"CulmenLength\", \"CulmenDepth\", \"FlipperLength\", \"BodyMass\"]\n",
    "     \n",
    "    # parameters\n",
    "    maxIterations = 5\n",
    "    regularization = 0.5\n",
    "   \n",
    "    # Define the feature engineering and model steps\n",
    "    catIndexer = StringIndexer(inputCol=catFeature, outputCol=catFeature + \"Idx\")\n",
    "    numVector = VectorAssembler(inputCols=numFeatures, outputCol=\"numericFeatures\")\n",
    "    numScaler = MinMaxScaler(inputCol = numVector.getOutputCol(), outputCol=\"normalizedFeatures\")\n",
    "    featureVector = VectorAssembler(inputCols=[\"IslandIdx\", \"normalizedFeatures\"], outputCol=\"Features\")\n",
    "    algo = LogisticRegression(labelCol=\"Species\", featuresCol=\"Features\", maxIter=maxIterations, regParam=regularization)\n",
    "   \n",
    "    # Chain the steps as stages in a pipeline\n",
    "    pipeline = Pipeline(stages=[catIndexer, numVector, numScaler, featureVector, algo])\n",
    "   \n",
    "    # Log training parameter values\n",
    "    print (\"Training Logistic Regression model...\")\n",
    "    mlflow.log_param('maxIter', algo.getMaxIter())\n",
    "    mlflow.log_param('regParam', algo.getRegParam())\n",
    "    model = pipeline.fit(train)\n",
    "      \n",
    "    # Evaluate the model and log metrics\n",
    "    prediction = model.transform(test)\n",
    "    metrics = [\"accuracy\", \"weightedRecall\", \"weightedPrecision\"]\n",
    "    for metric in metrics:\n",
    "        evaluator = MulticlassClassificationEvaluator(labelCol=\"Species\", predictionCol=\"prediction\", metricName=metric)\n",
    "        metricValue = evaluator.evaluate(prediction)\n",
    "        print(\"%s: %s\" % (metric, metricValue))\n",
    "        mlflow.log_metric(metric, metricValue)\n",
    "   \n",
    "           \n",
    "    # Log the model itself\n",
    "    unique_model_name = \"classifier-\" + str(time.time())\n",
    "    mlflow.spark.log_model(model, unique_model_name, mlflow.spark.get_default_conda_env())\n",
    "    modelpath = \"/Workspace/MicrosoftLearnings/model/%s\" % (unique_model_name)\n",
    "    mlflow.spark.savehttps://adb-385780289707858.18.azuredatabricks.net/editor/notebooks/3224834034575109?o=385780289707858$0_model(model, modelpath)\n",
    "       \n",
    "    print(\"Experiment run complete. And Model has been saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7f38ff4-f507-4789-8e67-7986371c2293",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create a function\n",
    "\n",
    "In machine learning projects, data scientists often try training models with different parameters, logging the results each time. To accomplish that, it’s common to create a function that encapsulates the training process and call it with the parameters you want to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd9279ed-0533-4e4b-be3d-8e311448b4a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_penguin_model(training_data, test_data, maxIterations, regularization):\n",
    "    import mlflow\n",
    "    import mlflow.spark\n",
    "    from pyspark.ml import Pipeline\n",
    "    from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "    from pyspark.ml.classification import LogisticRegression\n",
    "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "    import time\n",
    "\n",
    "    # End any active MLflow run\n",
    "    mlflow.end_run()\n",
    "    \n",
    "    # Start an MLflow run\n",
    "    with mlflow.start_run():\n",
    "   \n",
    "        catFeature = \"Island\"\n",
    "        numFeatures = [\"CulmenLength\", \"CulmenDepth\", \"FlipperLength\", \"BodyMass\"]\n",
    "   \n",
    "        # Define the feature engineering and model steps\n",
    "        catIndexer = StringIndexer(inputCol=catFeature, outputCol=catFeature + \"Idx\")\n",
    "        numVector = VectorAssembler(inputCols=numFeatures, outputCol=\"numericFeatures\")\n",
    "        numScaler = MinMaxScaler(inputCol = numVector.getOutputCol(), outputCol=\"normalizedFeatures\")\n",
    "        featureVector = VectorAssembler(inputCols=[\"IslandIdx\", \"normalizedFeatures\"], outputCol=\"Features\")\n",
    "        algo = LogisticRegression(labelCol=\"Species\", featuresCol=\"Features\", maxIter=maxIterations, regParam=regularization)\n",
    "   \n",
    "        # Chain the steps as stages in a pipeline\n",
    "        pipeline = Pipeline(stages=[catIndexer, numVector, numScaler, featureVector, algo])\n",
    "   \n",
    "        # Log training parameter values\n",
    "        print (\"Training Logistic Regression model...\")\n",
    "        mlflow.log_param('maxIter', algo.getMaxIter())\n",
    "        mlflow.log_param('regParam', algo.getRegParam())\n",
    "        model = pipeline.fit(training_data)\n",
    "   \n",
    "        # Evaluate the model and log metrics\n",
    "        prediction = model.transform(test_data)\n",
    "        metrics = [\"accuracy\", \"weightedRecall\", \"weightedPrecision\"]\n",
    "        for metric in metrics:\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"Species\", predictionCol=\"prediction\", metricName=metric)\n",
    "            metricValue = evaluator.evaluate(prediction)\n",
    "            print(\"%s: %s\" % (metric, metricValue))\n",
    "            mlflow.log_metric(metric, metricValue)\n",
    "   \n",
    "   \n",
    "        # Log the model itself\n",
    "        unique_model_name = \"classifier-\" + str(time.time())\n",
    "        mlflow.spark.log_model(model, unique_model_name, mlflow.spark.get_default_conda_env())\n",
    "        modelpath = \"/model/%s\" % (unique_model_name)\n",
    "        mlflow.spark.save_model(model, modelpath)\n",
    "   \n",
    "        print(\"Experiment run complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85fd13d1-54d2-4f32-b708-afe5cd148f76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# End any active MLflow run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd094238-873c-4825-81e6-4581ece84469",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model...\naccuracy: 0.9411764705882353\nweightedRecall: 0.9411764705882353\nweightedPrecision: 0.9480968858131488\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208f86086bb647aea8fa4bb3323dbc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment run complete.\n"
     ]
    }
   ],
   "source": [
    "train_penguin_model(train, test, 10, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7b0e0e5-25da-4cf5-849f-efa38b2461d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register and deploy a model with MLflow\n",
    "\n",
    "### You’ve already logged the model trained by each experiment run. \n",
    "### You can also register models and deploy them so they can be served to client applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "987ff1aa-d7d9-4d8d-ab0c-311931624df9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_penguin_model(training_data, test_data, maxIterations, regularization):\n",
    "    import mlflow\n",
    "    import mlflow.spark\n",
    "    from pyspark.ml import Pipeline\n",
    "    from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "    from pyspark.ml.classification import LogisticRegression\n",
    "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "    from mlflow.models.signature import infer_signature\n",
    "    import time\n",
    "\n",
    "    # End any active MLflow run\n",
    "    mlflow.end_run()\n",
    "    \n",
    "    # Start an MLflow run\n",
    "    with mlflow.start_run():\n",
    "   \n",
    "        catFeature = \"Island\"\n",
    "        numFeatures = [\"CulmenLength\", \"CulmenDepth\", \"FlipperLength\", \"BodyMass\"]\n",
    "   \n",
    "        # Define the feature engineering and model steps\n",
    "        catIndexer = StringIndexer(inputCol=catFeature, outputCol=catFeature + \"Idx\")\n",
    "        numVector = VectorAssembler(inputCols=numFeatures, outputCol=\"numericFeatures\")\n",
    "        numScaler = MinMaxScaler(inputCol = numVector.getOutputCol(), outputCol=\"normalizedFeatures\")\n",
    "        featureVector = VectorAssembler(inputCols=[\"IslandIdx\", \"normalizedFeatures\"], outputCol=\"Features\")\n",
    "        algo = LogisticRegression(labelCol=\"Species\", featuresCol=\"Features\", maxIter=maxIterations, regParam=regularization)\n",
    "   \n",
    "        # Chain the steps as stages in a pipeline\n",
    "        pipeline = Pipeline(stages=[catIndexer, numVector, numScaler, featureVector, algo])\n",
    "   \n",
    "        # Log training parameter values\n",
    "        print (\"Training Logistic Regression model...\")\n",
    "        mlflow.log_param('maxIter', algo.getMaxIter())\n",
    "        mlflow.log_param('regParam', algo.getRegParam())\n",
    "        model = pipeline.fit(training_data)\n",
    "   \n",
    "        # Evaluate the model and log metrics\n",
    "        prediction = model.transform(test_data)\n",
    "        metrics = [\"accuracy\", \"weightedRecall\", \"weightedPrecision\"]\n",
    "        for metric in metrics:\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"Species\", predictionCol=\"prediction\", metricName=metric)\n",
    "            metricValue = evaluator.evaluate(prediction)\n",
    "            print(\"%s: %s\" % (metric, metricValue))\n",
    "            mlflow.log_metric(metric, metricValue)\n",
    "   \n",
    "        # Infer model signature\n",
    "        input_example = training_data.limit(5).toPandas()\n",
    "        output_example = model.transform(training_data.limit(5)).toPandas()\n",
    "        signature = infer_signature(input_example, output_example)\n",
    "   \n",
    "        # Log the model itself with signature\n",
    "        unique_model_name = \"main.default.classifier-\" + str(time.time())\n",
    "        mlflow.spark.log_model(\n",
    "            model, \n",
    "            unique_model_name, \n",
    "            conda_env=mlflow.spark.get_default_conda_env(),\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "        modelpath = \"/model/%s\" % (unique_model_name)\n",
    "        mlflow.spark.save_model(model, modelpath)\n",
    "   \n",
    "        print(\"Experiment run complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "309ccbf9-f482-49d4-bb09-e4e5a8e3800b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model...\naccuracy: 0.9411764705882353\nweightedRecall: 0.9411764705882353\nweightedPrecision: 0.9480968858131488\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8020f8daef44738ccbed2cfe7591f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment run complete.\n"
     ]
    }
   ],
   "source": [
    "train_penguin_model(train, test, 15, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d412128-219a-4ead-872b-64aa0c5fb838",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register and deploy a model with MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7c44907-3651-4ebd-99e5-583ad95c2309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary of steps for registry of model with endpoint\n",
    "- Register Model - You will register the best model available\n",
    "- Use Model for Inference - You model will be made available with an endpoint having cluster/server/VM and you can send the in parameters in the json format to get the output in json format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63896f10-1ecf-42dd-8585-5e7bc6fa82b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Steps to follow\n",
    "- View the details page for the most recent experiment run.\n",
    "\n",
    "- Use the Register Model button to register the model that was logged in that experiment and when prompted, create a new model named Penguin Predictor.\n",
    "    - While Registering model use \"Workspace Model Registry\" and not \"Unity Catalog\", since it was throwing error\n",
    "    - Bad model name: please specify all three levels of the model in the form `catalog_name.schema_name.model_name`\n",
    "\n",
    "- When the model has been registered, view the Models page (in the navigation bar on the left) and submenu \"Workspace Model Registry\" and select the Penguin Predictor model.\n",
    "\n",
    "- In the page for the Penguin Predictor model, use the Use model for inference button to create a new real-time endpoint with the following settings:\n",
    "    - Model: Penguin Predictor\n",
    "    - Model version: 1\n",
    "    - Endpoint: predict-penguin\n",
    "    - Compute size: Small\n",
    "    \n",
    "The serving endpoint is hosted in a new cluster, which it may take several minutes to create.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a828290a-cf37-47bd-bc7c-ef02ebfe8d90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Clicks on screen\n",
    "Click on Serving > predict-penguin > Use > Browse > Provide input on LHS in JSON format > Click Send request > view output on RHS \n",
    "\n",
    "One of way sending the input\n",
    "Multiple data jsons can be created under data for each data row prediction in this one input alone \n",
    "\n",
    "**Input**\n",
    "\n",
    "{\n",
    "  \"dataframe_split\": {\n",
    "    \"columns\": [\n",
    "      \"Island\",\n",
    "      \"CulmenLength\",\n",
    "      \"CulmenDepth\",\n",
    "      \"FlipperLength\",\n",
    "      \"BodyMass\",\n",
    "      \"Species\"\n",
    "    ],\n",
    "    \"data\": [\n",
    "      [\n",
    "        \"Biscoe\",\n",
    "        48.7,\n",
    "        14.1,\n",
    "        210,\n",
    "        4450,\n",
    "        0\n",
    "      ]\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\n",
    "**Output**\n",
    "\n",
    "{\n",
    "  \"predictions\": [\n",
    "    1\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "927879af-13ce-4304-ac06-5a6266dba883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Another way of sending the same input\n",
    "\n",
    "**input**\n",
    "\n",
    " {\n",
    "   \"dataframe_records\": [\n",
    "   {\n",
    "      \"Island\": \"Biscoe\",\n",
    "      \"CulmenLength\": 48.7,\n",
    "      \"CulmenDepth\": 14.1,\n",
    "      \"FlipperLength\": 210,\n",
    "      \"BodyMass\": 4450,\n",
    "      \"Species\": 4450\n",
    "   }\n",
    "   ]\n",
    " }\n",
    "\n",
    " **output**\n",
    "\n",
    " {\n",
    "  \"predictions\": [\n",
    "    1\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0741d1e-060c-436a-a249-814681369048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2dee662b-a0e0-4d92-a095-47eeaa914070",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7446140396154196,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "4_Use MLflow in Azure Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}