{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a12412e-9fd7-4492-accb-06f76ef1cbc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manage machine learning in production with Azure Databricks\n"
     ]
    }
   ],
   "source": [
    "print('Manage machine learning in production with Azure Databricks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37a0cfb5-9939-4d46-9b09-738eaef098f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Provision an Azure Databricks workspace\n",
    "https://portal.azure.com > PowerShell\n",
    "\n",
    "## Remove the existing instance and download the installation setup file\n",
    "-      rm -r mslearn-databricks -f\n",
    "-      git clone https://github.com/MicrosoftLearning/mslearn-databricks\n",
    "\n",
    "## Setup a Azure Databricks workspace\n",
    "-      ./mslearn-databricks/setup.ps1\n",
    "-      ./mslearn-databricks/setup.ps1 eastus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b74b2c4e-749c-44e3-af0f-c30582991142",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " %sh\n",
    " rm -r /Workspace/MicrosoftLearnings/dbfs/ml_lab\n",
    " mkdir /Workspace/MicrosoftLearnings/dbfs/ml_lab\n",
    " wget -O /Workspace/MicrosoftLearnings/dbfs/ml_lab/penguins.csv https://raw.githubusercontent.com/MicrosoftLearning/mslearn-databricks/main/data/penguins.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1ae32d4-126e-4bf0-b9e2-d7796309a3be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Remove any incomplete rows\n",
    "- Apply appropriate data types\n",
    "- View a random sample of the data\n",
    "- Split the data into two datasets: one for training, and another for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a6b4cb8-881e-4c2b-bfe5-816ba246dae3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Island</th><th>CulmenLength</th><th>CulmenDepth</th><th>FlipperLength</th><th>BodyMass</th><th>Species</th></tr></thead><tbody><tr><td>Torgersen</td><td>39.5</td><td>17.4</td><td>186.0</td><td>3800.0</td><td>0</td></tr><tr><td>Torgersen</td><td>36.6</td><td>17.8</td><td>185.0</td><td>3700.0</td><td>0</td></tr><tr><td>Torgersen</td><td>46.0</td><td>21.5</td><td>194.0</td><td>4200.0</td><td>0</td></tr><tr><td>Biscoe</td><td>40.5</td><td>17.9</td><td>187.0</td><td>3200.0</td><td>0</td></tr><tr><td>Dream</td><td>40.9</td><td>18.9</td><td>184.0</td><td>3900.0</td><td>0</td></tr><tr><td>Dream</td><td>36.4</td><td>17.0</td><td>195.0</td><td>3325.0</td><td>0</td></tr><tr><td>Dream</td><td>39.6</td><td>18.8</td><td>190.0</td><td>4600.0</td><td>0</td></tr><tr><td>Dream</td><td>36.0</td><td>17.9</td><td>190.0</td><td>3450.0</td><td>0</td></tr><tr><td>Biscoe</td><td>34.5</td><td>18.1</td><td>187.0</td><td>2900.0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Torgersen",
         39.5,
         17.4,
         186.0,
         3800.0,
         0
        ],
        [
         "Torgersen",
         36.6,
         17.8,
         185.0,
         3700.0,
         0
        ],
        [
         "Torgersen",
         46.0,
         21.5,
         194.0,
         4200.0,
         0
        ],
        [
         "Biscoe",
         40.5,
         17.9,
         187.0,
         3200.0,
         0
        ],
        [
         "Dream",
         40.9,
         18.9,
         184.0,
         3900.0,
         0
        ],
        [
         "Dream",
         36.4,
         17.0,
         195.0,
         3325.0,
         0
        ],
        [
         "Dream",
         39.6,
         18.8,
         190.0,
         4600.0,
         0
        ],
        [
         "Dream",
         36.0,
         17.9,
         190.0,
         3450.0,
         0
        ],
        [
         "Biscoe",
         34.5,
         18.1,
         187.0,
         2900.0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Island",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CulmenLength",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "CulmenDepth",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "FlipperLength",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "BodyMass",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "Species",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 232  Testing Rows: 110\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "   \n",
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"file:/Workspace/MicrosoftLearnings/dbfs/ml_lab/penguins.csv\")\n",
    "data = data.dropna().select(col(\"Island\").astype(\"string\"),\n",
    "                          col(\"CulmenLength\").astype(\"float\"),\n",
    "                          col(\"CulmenDepth\").astype(\"float\"),\n",
    "                          col(\"FlipperLength\").astype(\"float\"),\n",
    "                          col(\"BodyMass\").astype(\"float\"),\n",
    "                          col(\"Species\").astype(\"int\")\n",
    "                          )\n",
    "display(data.sample(0.2).limit(9))\n",
    "   \n",
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "print (\"Training Rows:\", train.count(), \" Testing Rows:\", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d71acf72-8342-48ef-b3be-ed4787a46a39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Run a pipeline to preprocess the data and train a ML model\n",
    "Create a pipeline that encapsulates the data preparation and model training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62193523-02e2-49e5-b8c9-7e372cf219f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e34cd169764367b95f68e4b8561926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd310ea1e20a415eafbbcbd618dadf4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "catFeature = \"Island\"\n",
    "numFeatures = [\"CulmenLength\", \"CulmenDepth\", \"FlipperLength\", \"BodyMass\"]\n",
    "\n",
    "# Define the feature engineering and model training algorithm steps\n",
    "catIndexer = StringIndexer(inputCol=catFeature, outputCol=catFeature + \"Idx\")\n",
    "numVector = VectorAssembler(inputCols=numFeatures, outputCol=\"numericFeatures\")\n",
    "numScaler = MinMaxScaler(inputCol = numVector.getOutputCol(), outputCol=\"normalizedFeatures\")\n",
    "featureVector = VectorAssembler(inputCols=[\"IslandIdx\", \"normalizedFeatures\"], outputCol=\"Features\")\n",
    "algo = LogisticRegression(labelCol=\"Species\", featuresCol=\"Features\", maxIter=10, regParam=0.3)\n",
    "\n",
    "# Chain the steps as stages in a pipeline\n",
    "pipeline = Pipeline(stages=[catIndexer, numVector, numScaler, featureVector, algo])\n",
    "\n",
    "# Use the pipeline to prepare data and fit the model algorithm\n",
    "model = pipeline.fit(train)\n",
    "print (\"Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "211b60e4-9bf3-4d75-8154-bd9f152c0455",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Since the feature engineering steps are now encapsulated in the model trained by the pipeline, you can use the model with the test data without needing to apply each transformation (they’ll be applied automatically by the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32279fb8-f44a-4ba4-a34e-0356347a27e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Features</th><th>probability</th><th>prediction</th><th>trueLabel</th></tr></thead><tbody><tr><td>Map(vectorType -> dense, length -> 5, values -> List(0.0, 0.11196916428677685, 0.5662650242480307, 0.3050847457627119, 0.17391304347826086))</td><td>Map(vectorType -> dense, length -> 3, values -> List(0.8132791379729964, 0.08841165912898039, 0.09830920289802322))</td><td>0</td><td>0</td></tr><tr><td>Map(vectorType -> dense, length -> 5, values -> List(0.0, 0.13899621917864713, 0.44578309930587445, 0.22033898305084745, 0.08695652173913043))</td><td>Map(vectorType -> dense, length -> 3, values -> List(0.7979285681723355, 0.0911639776714057, 0.1109074541562589))</td><td>0</td><td>0</td></tr><tr><td>Map(vectorType -> dense, length -> 5, values -> List(0.0, 0.2239383285735537, 0.6506024636279539, 0.3559322033898305, 0.021739130434782608))</td><td>Map(vectorType -> dense, length -> 3, values -> List(0.7587373093298683, 0.07965878354444202, 0.16160390712568964))</td><td>0</td><td>0</td></tr><tr><td>Map(vectorType -> dense, length -> 5, values -> List(0.0, 0.23552131001704094, 0.5903615011568758, 0.22033898305084745, 0.3188405797101449))</td><td>Map(vectorType -> dense, length -> 3, values -> List(0.7464927703180938, 0.11808419061109462, 0.13542303907081163))</td><td>0</td><td>0</td></tr><tr><td>Map(vectorType -> dense, length -> 5, values -> List(0.0, 0.23552131001704094, 0.8192771125867657, 0.3050847457627119, 0.30434782608695654))</td><td>Map(vectorType -> dense, length -> 3, values -> List(0.7793882120251684, 0.07901757557520417, 0.14159421239962738))</td><td>0</td><td>0</td></tr><tr><td>Map(vectorType -> dense, length -> 5, values -> List(0.0, 0.26640930962820697, 0.5180723002313752, 0.23728813559322035, 0.20289855072463767))</td><td>Map(vectorType -> dense, length -> 3, values -> List(0.7120211413673391, 0.12748277120140786, 0.16049608743125304))</td><td>0</td><td>0</td></tr><tr><td>Map(vectorType -> dense, length -> 5, values -> List(0.0, 0.28957527251518145, 0.5421687771402204, 0.23728813559322035, 0.18840579710144928))</td><td>Map(vectorType -> dense, length -> 3, values -> List(0.701795379099593, 0.12316419338682807, 0.1750404275135789))</td><td>0</td><td>0</td></tr><tr><td>Map(vectorType -> dense, length -> 5, values -> List(0.0, 0.28957527251518145, 0.9036145519666889, 0.3220338983050847, 0.30434782608695654))</td><td>Map(vectorType -> dense, length -> 3, values -> List(0.7540350409831782, 0.07485546990712295, 0.17110948910969895))</td><td>0</td><td>0</td></tr><tr><td>Map(vectorType -> dense, length -> 5, values -> List(0.0, 0.2934363645200772, 0.5421687771402204, 0.3559322033898305, 0.10144927536231883))</td><td>Map(vectorType -> dense, length -> 3, values -> List(0.6732003750792119, 0.13610095268767874, 0.19069867223310918))</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         {
          "length": 5,
          "values": [
           0.0,
           0.11196916428677685,
           0.5662650242480307,
           0.3050847457627119,
           0.17391304347826086
          ],
          "vectorType": "dense"
         },
         {
          "length": 3,
          "values": [
           0.8132791379729964,
           0.08841165912898039,
           0.09830920289802322
          ],
          "vectorType": "dense"
         },
         0,
         0
        ],
        [
         {
          "length": 5,
          "values": [
           0.0,
           0.13899621917864713,
           0.44578309930587445,
           0.22033898305084745,
           0.08695652173913043
          ],
          "vectorType": "dense"
         },
         {
          "length": 3,
          "values": [
           0.7979285681723355,
           0.0911639776714057,
           0.1109074541562589
          ],
          "vectorType": "dense"
         },
         0,
         0
        ],
        [
         {
          "length": 5,
          "values": [
           0.0,
           0.2239383285735537,
           0.6506024636279539,
           0.3559322033898305,
           0.021739130434782608
          ],
          "vectorType": "dense"
         },
         {
          "length": 3,
          "values": [
           0.7587373093298683,
           0.07965878354444202,
           0.16160390712568964
          ],
          "vectorType": "dense"
         },
         0,
         0
        ],
        [
         {
          "length": 5,
          "values": [
           0.0,
           0.23552131001704094,
           0.5903615011568758,
           0.22033898305084745,
           0.3188405797101449
          ],
          "vectorType": "dense"
         },
         {
          "length": 3,
          "values": [
           0.7464927703180938,
           0.11808419061109462,
           0.13542303907081163
          ],
          "vectorType": "dense"
         },
         0,
         0
        ],
        [
         {
          "length": 5,
          "values": [
           0.0,
           0.23552131001704094,
           0.8192771125867657,
           0.3050847457627119,
           0.30434782608695654
          ],
          "vectorType": "dense"
         },
         {
          "length": 3,
          "values": [
           0.7793882120251684,
           0.07901757557520417,
           0.14159421239962738
          ],
          "vectorType": "dense"
         },
         0,
         0
        ],
        [
         {
          "length": 5,
          "values": [
           0.0,
           0.26640930962820697,
           0.5180723002313752,
           0.23728813559322035,
           0.20289855072463767
          ],
          "vectorType": "dense"
         },
         {
          "length": 3,
          "values": [
           0.7120211413673391,
           0.12748277120140786,
           0.16049608743125304
          ],
          "vectorType": "dense"
         },
         0,
         0
        ],
        [
         {
          "length": 5,
          "values": [
           0.0,
           0.28957527251518145,
           0.5421687771402204,
           0.23728813559322035,
           0.18840579710144928
          ],
          "vectorType": "dense"
         },
         {
          "length": 3,
          "values": [
           0.701795379099593,
           0.12316419338682807,
           0.1750404275135789
          ],
          "vectorType": "dense"
         },
         0,
         0
        ],
        [
         {
          "length": 5,
          "values": [
           0.0,
           0.28957527251518145,
           0.9036145519666889,
           0.3220338983050847,
           0.30434782608695654
          ],
          "vectorType": "dense"
         },
         {
          "length": 3,
          "values": [
           0.7540350409831782,
           0.07485546990712295,
           0.17110948910969895
          ],
          "vectorType": "dense"
         },
         0,
         0
        ],
        [
         {
          "length": 5,
          "values": [
           0.0,
           0.2934363645200772,
           0.5421687771402204,
           0.3559322033898305,
           0.10144927536231883
          ],
          "vectorType": "dense"
         },
         {
          "length": 3,
          "values": [
           0.6732003750792119,
           0.13610095268767874,
           0.19069867223310918
          ],
          "vectorType": "dense"
         },
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"ml_attr\":{\"attrs\":{\"numeric\":[{\"idx\":1,\"name\":\"normalizedFeatures_0\"},{\"idx\":2,\"name\":\"normalizedFeatures_1\"},{\"idx\":3,\"name\":\"normalizedFeatures_2\"},{\"idx\":4,\"name\":\"normalizedFeatures_3\"}],\"nominal\":[{\"vals\":[\"Biscoe\",\"Dream\",\"Torgersen\"],\"idx\":0,\"name\":\"IslandIdx\"}]},\"num_attrs\":5}}",
         "name": "Features",
         "type": "{\"type\":\"udt\",\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"type\",\"type\":\"byte\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"indices\",\"type\":{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}},{\"name\":\"values\",\"type\":{\"type\":\"array\",\"elementType\":\"double\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}}]}}"
        },
        {
         "metadata": "{\"ml_attr\":{\"num_attrs\":3}}",
         "name": "probability",
         "type": "{\"type\":\"udt\",\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"type\",\"type\":\"byte\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"indices\",\"type\":{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}},{\"name\":\"values\",\"type\":{\"type\":\"array\",\"elementType\":\"double\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}}]}}"
        },
        {
         "metadata": "{}",
         "name": "prediction",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "trueLabel",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9545454545454546\n\nIndividual class metrics:\nClass 0\n\tPrecision: 0.9074074074074074\n\tRecall: 1.0\n\tF1 Score: 0.9514563106796117\nClass 1\n\tPrecision: 1.0\n\tRecall: 1.0\n\tF1 Score: 1.0\nClass 2\n\tPrecision: 1.0\n\tRecall: 0.7619047619047619\n\tF1 Score: 0.8648648648648648\nOverall Precision: 0.9587542087542087\nOverall Recall: 0.9545454545454545\nOverall F1 Score: 0.952577467140574\n"
     ]
    }
   ],
   "source": [
    "# Apply the pipeline to the test data and evaluate the model\n",
    "\n",
    "prediction = model.transform(test)\n",
    "predicted = prediction.select(\"Features\", \"probability\", col(\"prediction\").astype(\"Int\"), col(\"Species\").alias(\"trueLabel\"))\n",
    "display(predicted.limit(9))\n",
    "\n",
    "# Generate evaluation metrics\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Species\", predictionCol=\"prediction\")\n",
    "\n",
    "# Simple accuracy\n",
    "accuracy = evaluator.evaluate(prediction, {evaluator.metricName:\"accuracy\"})\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Class metrics\n",
    "labels = [0,1,2]\n",
    "print(\"\\nIndividual class metrics:\")\n",
    "for label in sorted(labels):\n",
    "    print (\"Class %s\" % (label))\n",
    "   \n",
    "    # Precision\n",
    "    precision = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                                    evaluator.metricName:\"precisionByLabel\"})\n",
    "    print(\"\\tPrecision:\", precision)\n",
    "   \n",
    "    # Recall\n",
    "    recall = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                             evaluator.metricName:\"recallByLabel\"})\n",
    "    print(\"\\tRecall:\", recall)\n",
    "   \n",
    "    # F1 score\n",
    "    f1 = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                         evaluator.metricName:\"fMeasureByLabel\"})\n",
    "    print(\"\\tF1 Score:\", f1)\n",
    "   \n",
    "# Weighed (overall) metrics\n",
    "overallPrecision = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedPrecision\"})\n",
    "print(\"Overall Precision:\", overallPrecision)\n",
    "overallRecall = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedRecall\"})\n",
    "print(\"Overall Recall:\", overallRecall)\n",
    "overallF1 = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedFMeasure\"})\n",
    "print(\"Overall F1 Score:\", overallF1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7f8577b-5383-4feb-8c5c-173e651513f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Register and deploy the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9819e2da-61e3-4614-a479-da18f92761ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You’ve already logged the model trained by each experiment run when you ran the pipeline. You can also register models and deploy them so they can be served to client applications."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "8_Manage machine learning in production with Azure Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}